{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:12.753971Z",
     "start_time": "2020-04-30T11:56:12.742305Z"
    }
   },
   "source": [
    "## Implementation of Neural style transfer\n",
    "References:\n",
    "- https://arxiv.org/pdf/1508.06576.pdf\n",
    "- https://keras.io/examples/neural_style_transfer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:50.715796Z",
     "start_time": "2020-04-30T11:56:50.711709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set paths to your files\n",
    "content_image_path = './content_image.jpg'\n",
    "style_image_path = './style_image.jpg'\n",
    "output_image_path = './generated_image.jpg'\n",
    "\n",
    "# which VGG19 layers to user for style cost\n",
    "style_layers_names = [\n",
    "    ('block1_conv1'),\n",
    "    ('block2_conv1'),\n",
    "    ('block3_conv1'),\n",
    "    ('block4_conv1'),\n",
    "    ('block5_conv1')]\n",
    "\n",
    "# component weights in loss function\n",
    "total_variation_weight = 2e2\n",
    "style_weight = 1e2\n",
    "content_weight = 7.5e0\n",
    "\n",
    "# num of iterations for optimization\n",
    "iters = 20\n",
    "\n",
    "# number of rows for the generated picture\n",
    "img_nrows = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:51.508117Z",
     "start_time": "2020-04-30T11:56:51.500580Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG19\n",
    "from keras.preprocessing.image import load_img, save_img\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:52.145544Z",
     "start_time": "2020-04-30T11:56:52.138896Z"
    }
   },
   "outputs": [],
   "source": [
    "def noise_image(content_image, img_nrows, img_ncols, noise_ratio=.3):\n",
    "    \"\"\"\n",
    "    Given a content image tensor add random noise and return image\n",
    "    \"\"\"\n",
    "    noise_image = np.random.uniform(-20, 20, (1, img_nrows, img_ncols, 3)).astype('float32')\n",
    "    input_image = noise_image * noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:52.618698Z",
     "start_time": "2020-04-30T11:56:52.614450Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_content_cost(content_activation, generated_content_activation):\n",
    "    \"\"\"\n",
    "    Given the content activation and generated picture activation of the same conv layer\n",
    "    return cost over all elements\n",
    "    \"\"\"\n",
    "    return K.sum(K.square(generated_content_activation - content_activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:52.853943Z",
     "start_time": "2020-04-30T11:56:52.848784Z"
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    \"\"\"\n",
    "    Given a tensor return the gram matrix\n",
    "    \"\"\"\n",
    "    features = K.batch_flatten(K.permute_dimensions(A, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:53.043825Z",
     "start_time": "2020-04-30T11:56:53.038274Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_layer_style_cost(style_activation, generated_activation):\n",
    "    \"\"\"\n",
    "    Given the style activation and generated picture activation of the same conv layer\n",
    "    return the loss as distance of the gram matrices of both activations\n",
    "    \"\"\"\n",
    "    W, H, C = img_ncols, img_nrows, 3\n",
    "    GS = gram_matrix(style_activation)\n",
    "    GG = gram_matrix(generated_activation)\n",
    "    factor = 1. / float(2 * C * H * W) ** 2\n",
    "    return factor * K.sum(K.square(GG - GS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:53.223416Z",
     "start_time": "2020-04-30T11:56:53.216794Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_style_cost(style_layers):\n",
    "    \"\"\"\n",
    "    Given the activation of multiple conv layers\n",
    "    return the weighted sum of the individual style layer cost\n",
    "    \"\"\"\n",
    "    # intialize loss\n",
    "    J_style = 0\n",
    "    # all layers are equally weighted (simple)\n",
    "    layer_weight = 1. / len(style_layers)\n",
    "\n",
    "    # loop over style layers to increment loss\n",
    "    for layer in style_layers:\n",
    "        style_activation = layer[1, :, :, :]\n",
    "        generated_activation = layer[2, :, :, :]\n",
    "\n",
    "        # Compute style_cost for the current layer\n",
    "        J_style += layer_weight * compute_layer_style_cost(style_activation,\n",
    "                                                           generated_activation)\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:53.392131Z",
     "start_time": "2020-04-30T11:56:53.385221Z"
    }
   },
   "outputs": [],
   "source": [
    "def variation_loss(generated_image):\n",
    "    \"\"\"\n",
    "    return variation loss given current image generated, smoothes image\n",
    "    \"\"\"\n",
    "    a = K.square(generated_image[:, :img_nrows-1, :img_ncols-1,\n",
    "                                 :] - generated_image[:, 1:, :img_ncols-1, :])\n",
    "    b = K.square(generated_image[:, :img_nrows-1, :img_ncols-1,\n",
    "                                 :] - generated_image[:, :img_nrows-1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:53.934960Z",
     "start_time": "2020-04-30T11:56:53.927842Z"
    }
   },
   "outputs": [],
   "source": [
    "def total_cost(content_layers, \n",
    "               style_layers, \n",
    "               generated_image, \n",
    "               total_variation_weight, \n",
    "               style_weight, \n",
    "               content_weight):\n",
    "    \"\"\"\n",
    "    given the activation of content layer and style layers for generated and input pics\n",
    "    return weighted total loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Content cost - grab the correct activations from the content tensor\n",
    "    content_activation = content_layers[0, :, :, :]\n",
    "    generated_content_activation = content_layers[2, :, :, :]\n",
    "    J_content = compute_content_cost(content_activation, generated_content_activation)\n",
    "    \n",
    "    # 2. Style cost - compute the syle cost over all style layers\n",
    "    J_style = compute_style_cost(style_layers)\n",
    "    \n",
    "    # 3. Total variation loss - compute the total variation loss\n",
    "    J_vloss = variation_loss(generated_image)\n",
    "    \n",
    "    return content_weight * J_content + style_weight * J_style + total_variation_weight * J_vloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:54.270785Z",
     "start_time": "2020-04-30T11:56:54.265200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_layers(model, style_layers_names):\n",
    "    \"\"\"\n",
    "    given (VGG19) mode, return the desired style and content layers\n",
    "    \"\"\" \n",
    "    layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "    content_layers = layers['block4_conv2'] # hard coded content layer\n",
    "    style_layers = [layers[layer] for layer in style_layers_names]\n",
    "    return content_layers, style_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:54.753384Z",
     "start_time": "2020-04-30T11:56:54.745466Z"
    }
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    \"\"\"\n",
    "    Evaluator class used to track gradients and loss values together\n",
    "    Reference: https://keras.io/examples/neural_style_transfer/ \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        \n",
    "        generated = x\n",
    "        generated = generated.reshape((1, img_nrows, img_ncols, 3))\n",
    "        outs = f_outputs([generated])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        \n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:55.546319Z",
     "start_time": "2020-04-30T11:56:55.539552Z"
    }
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    \"\"\"\n",
    "    Remove zero center and reorder to RGB\n",
    "    Reference: https://keras.io/examples/neural_style_transfer/ \n",
    "    \"\"\"\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:56.092652Z",
     "start_time": "2020-04-30T11:56:56.087113Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image(path, img_nrows, img_ncols):\n",
    "    \"\"\"\n",
    "    given path, load image, scale, exand and perform VGG19 preprocessing\n",
    "    \"\"\"\n",
    "    img = load_img(path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-30T11:58:24.578Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dimensions for output picture\n",
    "width, height = load_img(content_image_path).size\n",
    "img_ncols = int(width * img_nrows / height)\n",
    "\n",
    "# preprocess content and style picture\n",
    "content_image = preprocess_image(content_image_path, img_nrows, img_ncols)\n",
    "style_image = preprocess_image(style_image_path, img_nrows, img_ncols)\n",
    "\n",
    "# generate Keras variables for pictures\n",
    "content_image = K.variable(content_image)\n",
    "style_image = K.variable(style_image)\n",
    "generated_image = K.placeholder((1, img_nrows, img_ncols, 3))\n",
    "\n",
    "# initalize cost variable\n",
    "cost = K.variable(0)\n",
    "\n",
    "# input tensor will concist of c, s and g pics\n",
    "input_tensor = K.concatenate(\n",
    "    [content_image, style_image, generated_image], axis=0)\n",
    "\n",
    "# import VGG19 model\n",
    "model = VGG19(input_tensor=input_tensor,\n",
    "              weights='imagenet', include_top=False)\n",
    "\n",
    "# get layers on which content and styles loss is computed\n",
    "content_layers, style_layers = get_layers(model, style_layers_names)\n",
    "\n",
    "# initialize cost\n",
    "cost = total_cost(content_layers, style_layers,\n",
    "                  generated_image, total_variation_weight, style_weight, content_weight)\n",
    "\n",
    "# Initialize gradients, Keras function and Evaluator\n",
    "grads = K.gradients(cost, generated_image)[0]\n",
    "f_outputs = K.function([generated_image], [cost, grads])\n",
    "evaluator = Evaluator()\n",
    "\n",
    "# currently generated image starting point is content image, but can add noise\n",
    "generated_img = preprocess_image(content_image_path, img_nrows, img_ncols)\n",
    "\n",
    "for i in tqdm(range(iters)):\n",
    "    generated_img, min_val, info = fmin_l_bfgs_b(evaluator.loss, generated_img,\n",
    "                                                 fprime=evaluator.grads, maxfun=20)\n",
    "    img = deprocess_image(generated_img.copy())\n",
    "    imageio.imwrite(output_image_path, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
